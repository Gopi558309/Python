{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPljH+/7UYR4HvW2idYsY4G",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Gopi558309/Python/blob/main/Gemini_ai_Video_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "nIY2qVddrLkQ",
        "outputId": "d5517552-ab78-40bf-a0f2-fbd133dae119"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'Image' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-dd1edcfc7fba>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mImange_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"product.jpg\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImange_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"What product is shown in this image?\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Image' is not defined"
          ]
        }
      ],
      "source": [
        "Imange_path = \"product.jpg\"\n",
        "image = Image.open(Imange_path)\n",
        "response = model.generate_context([\"What product is shown in this image?\",image])\n",
        "print(response.text)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = model.generate_context([\"What product is shown in this image?\",image])\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "id": "i8CErPj6uMxe",
        "outputId": "452472b5-ae60-4ff8-eb76-11e782252228"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'model' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-6b0a45452de0>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"What product is shown in this image?\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = model.generate_context([\"What product is shown in this image?\",image])\n",
        "print(response.text)\n",
        "Imange_path = \"product.jpg\"\n",
        "image = Image.open(Imange_path)\n",
        "response = model.generate_context([\"What product is shown in this image?\",image])\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "t8gOm-o3uM-Q",
        "outputId": "b8ee8922-5d71-4c3a-de23-f13c64e0a977"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'model' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-eb2459a10530>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"What product is shown in this image?\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mImange_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"product.jpg\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImange_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"What product is shown in this image?\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Imange_path = \"bicycle.jpg\"\n",
        "# Change to your image file\n",
        "image = Image.open(Imange_path)\n",
        "response = model.generate_context([\"What product is shown in this image?\",image])\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "BOx28z1suNK3",
        "outputId": "8084a781-0a9a-4b42-b1a1-7a781ff14f11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'Image' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-ddc6b40d7d8e>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mImange_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"bicycle.jpg\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Change to your image file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImange_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"What product is shown in this image?\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Image' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install youtube-transcript-api pytube"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lKLgt6FHyMWg",
        "outputId": "0ac83d49-0f38-4bf9-c0de-bd21a1c86b30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting youtube-transcript-api\n",
            "  Downloading youtube_transcript_api-1.0.1-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting pytube\n",
            "  Downloading pytube-15.0.0-py3-none-any.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from youtube-transcript-api) (0.7.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from youtube-transcript-api) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->youtube-transcript-api) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->youtube-transcript-api) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->youtube-transcript-api) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->youtube-transcript-api) (2025.1.31)\n",
            "Downloading youtube_transcript_api-1.0.1-py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytube-15.0.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pytube, youtube-transcript-api\n",
            "Successfully installed pytube-15.0.0 youtube-transcript-api-1.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from youtube_transcript_api import YouTubeTranscriptApi\n",
        "def get_youtube_transcript(video_id):\n",
        "    video_id = video_url.split\n",
        "    transcript = \" \".join([d['text'] for d in transcript_list])\n",
        "    return"
      ],
      "metadata": {
        "id": "y-GAD_MhyMiO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def summarize_video(text):\n",
        "  \"\"\"Summarize the youtube video transcript using Gemini AI.\"\"\"\n",
        "  model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
        "  prompt = f\"Summarize the following Youtube video transcript:\\n\\n{text}\""
      ],
      "metadata": {
        "id": "gi3_bPGNyMxO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def summarize_video(text):\n",
        "  \"\"\"Summarize the youtube video transcript using Gemini AI.\"\"\"\n",
        "  model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
        "  prompt = f\"Summarize the following Youtube video transcript:\\n\\n{text}\""
      ],
      "metadata": {
        "id": "SDkGzUUI2As1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\n",
        "genai.configure(api_key=GOOGLE_API_KEY)"
      ],
      "metadata": {
        "id": "BylDye0K6wyT"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image # Import the Image module from PIL\n",
        "\n",
        "image_path = \"Headphones.jpg\"\n",
        "image = Image.open(image_path) # Now you can use the Image object\n",
        "model = genai.GenerativeModel('gemini-1.5-flash')\n",
        "response = model.generate_content([\"What product is shown in this image?\",image])\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "yzpqr_4W8PY5",
        "outputId": "e68a9c1c-e797-4620-9d3d-247a10e23fee"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "That's a pair of black over-ear headphones.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = model.generate_content([\"Suggest similar products to this one.\", image])\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "b7B963vl9iRi",
        "outputId": "ed77b197-1a59-4e91-8f37-6ca2456df328"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here are some similar products to the pictured black over-ear headphones.  To give you the most relevant suggestions, I need more information.  However, I can suggest based on the image's appearance:\n",
            "\n",
            "**General Similar Products (based on appearance):**\n",
            "\n",
            "* **Other Over-Ear Headphones:**  Look for over-ear headphones in a similar style.  Many brands offer black over-ear headphones with a similar design aesthetic. Search for \"over-ear headphones black\" on major online retailers like Amazon, Best Buy, or your preferred electronics store.  Consider brands like Sony, Bose, Audio-Technica, Sennheiser, JBL, and Skullcandy.\n",
            "* **Noise-Cancelling Headphones:** The image suggests the possibility of noise-canceling capabilities due to the earcup design, although it's not certain.  Searching for \"noise-canceling over-ear headphones\" would yield similar options with added features.\n",
            "* **Wireless Headphones (Possibly):** While not explicitly shown, it's possible the headphones are wireless. Searching for \"wireless over-ear headphones black\" would provide relevant results.\n",
            "\n",
            "**To get more specific recommendations, tell me:**\n",
            "\n",
            "* **Your budget:** How much are you willing to spend?\n",
            "* **Desired features:** Are you looking for noise-cancellation, Bluetooth connectivity, a microphone, a specific sound signature (bass-heavy, balanced, etc.), water resistance, or other features?\n",
            "* **Use case:** Will you be using these for commuting, working from home, gaming, or something else?  This influences desired features like microphone quality or comfort level.\n",
            "\n",
            "\n",
            "Once I have this information, I can give you much more tailored and helpful suggestions.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = \"invoice.jpg\"\n",
        "image = Image.open(image_path)\n",
        "response = model.generate_content([\"Extract the price from this image.\", image])\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "_oWRI7ko_JMI",
        "outputId": "56967240-ea9b-400f-af5f-1fb12ce5e9b8"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The price of each item is $10.00.  The subtotal is $100.00, and the grand total, including a 10% tax, is also $100.00.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = model.generate_content([\"Extract the price, currency, and any discounts from this image.\", image])\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "id": "PaVJCXMH_83T",
        "outputId": "fcdd5101-ec7e-4bb6-a82e-e6ad2e05f569"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here's the extracted information from the image:\n",
            "\n",
            "* **Price:** $10.00 (per item)\n",
            "* **Currency:** USD ($)\n",
            "* **Discounts:** None listed.  There is a 10% tax, but this is not a discount.  The grand total remains $100.00, suggesting that this tax may be included in the price, rather than being added on separately.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = \"bicycle.jpg\"\n",
        "image = Image.open(image_path)\n",
        "response = model.generate_content([\"Identify all the objects in this image.\", image])\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "kpUwRiuBAZxh",
        "outputId": "930fd0da-6dde-49ca-d57e-9fa91630fdba"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here are the objects I identify in the image:\n",
            "\n",
            "* **Two bicycles:** One is mostly yellow and black, the other is white.\n",
            "* **Two men:** Riding the bicycles. One is wearing a blue shirt and camouflage shorts, the other a grey long-sleeved shirt and jeans and a red cap.\n",
            "* **A motorcycle:** Parked on the left side of the image.\n",
            "* **A man (in the background):** Sitting in a chair inside a building.\n",
            "* **Two chairs:** Visible inside the building behind the cyclists.\n",
            "* **A building:**  With a roll-up door, windows, and a small porch.\n",
            "* **A street:** Wet from rain.\n",
            "* **Some vegetation:**  Along the side of the road.\n",
            "* **A water bottle:** Attached to one of the bicycles.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = \"food.jpg\"\n",
        "image = Image.open(image_path)\n",
        "response = model.generate_content([\"Give the names of the objects and how many of same kind are there.Note:There are 5 tomatoes\", image])\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "id": "0vCGBuGSBPrT",
        "outputId": "a035110b-bb5b-444d-b9e4-83f067ff1190"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here's a list of the countable objects and their quantities:\n",
            "\n",
            "* **Eggs:** 3\n",
            "* **Olives:** 2\n",
            "* **Fries:** 1 (serving)\n",
            "* **Burger:** 1\n",
            "* **Hot dog:** 1\n",
            "* **Apple:** 1\n",
            "* **Carrots:** 2\n",
            "* **Tomatoes:** 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install youtube-transcript-api pytube"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MtNv7c2UChdY",
        "outputId": "58b6ec58-cf52-4a89-ba35-b06d645d482c"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: youtube-transcript-api in /usr/local/lib/python3.11/dist-packages (1.0.1)\n",
            "Requirement already satisfied: pytube in /usr/local/lib/python3.11/dist-packages (15.0.0)\n",
            "Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from youtube-transcript-api) (0.7.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from youtube-transcript-api) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->youtube-transcript-api) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->youtube-transcript-api) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->youtube-transcript-api) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->youtube-transcript-api) (2025.1.31)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from youtube_transcript_api import YouTubeTranscriptApi\n",
        "\n",
        "def get_youtube_transcript(video_url):\n",
        "\n",
        "    \"\"\"Fetches the transcript of a YouTube video.\"\"\"\n",
        "\n",
        "    video_id = video_url.split(\"v=\")[1].split(\"&\")[0]\n",
        "\n",
        "    transcript = YouTubeTranscriptApi.get_transcript(video_id)\n",
        "\n",
        "    full_text = \" \".join([t[\"text\"] for t in transcript])\n",
        "\n",
        "    return full_text\n",
        "video_url = \"https://www.youtube.com/watch?v=unYDoA8QGH0&list=PLWEpztHwA4ZT2QlHC74oIz4MsawcvE-QX\"\n",
        "video_transcript = get_youtube_transcript(video_url)\n",
        "print(\"Transcript:\\n\", video_transcript[:500])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zS5G2-jFDEtA",
        "outputId": "4a7ef961-d3db-4dd3-eed8-3af44868d27f"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcript:\n",
            " hi guys today I'm going to introduce you what is machine learning uh these are my presentation content what is machine learning what are the different applications of machine learning different types of machine learning and how to build a machine learning system or model then various kinds of algorithms and later on in this series we are going to take a Hands-On you know case studies or doing programming for various kinds of up algorithms so what is machine learning so machine learning is nothin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def summarize_video(text):\n",
        "\n",
        "    \"\"\"Summarizes the YouTube video transcript using Gemini AI.\"\"\"\n",
        "\n",
        "    model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
        "\n",
        "    prompt = f\"Summarize the following YouTube video transcript:\\n\\n{text}\"\n",
        "\n",
        "    response = model.generate_content(prompt)\n",
        "\n",
        "    return response.text\n",
        "\n",
        "summary = summarize_video(video_transcript)\n",
        "\n",
        "print(\"Summary:\\n\", summary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "id": "KAVkpz3EE1nn",
        "outputId": "4b051968-b295-45a6-a873-037867dd663d"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summary:\n",
            " This YouTube video provides an introduction to machine learning.  It covers the definition of machine learning as learning from data, emphasizing its role as a subfield of artificial intelligence.  The presenter outlines various applications (speech recognition, web search, recommendation systems, computer vision, fraud detection, and information retrieval), and categorizes machine learning into three types: supervised, unsupervised, and reinforcement learning.\n",
            "\n",
            "Supervised learning uses labeled data to predict outcomes (classification for categorical data, regression for continuous data). Unsupervised learning explores unlabeled data to find patterns (clustering and dimensionality reduction). Reinforcement learning involves an agent learning through trial and error within an environment, receiving rewards or penalties.\n",
            "\n",
            "The video also details the process of building a machine learning model, including data pre-processing (cleaning, scaling, encoding, feature selection), algorithm selection, model building, and evaluation.  The presenter mentions specific algorithms (decision trees, random forests, k-nearest neighbors) and highlights the importance of building multiple models for comparison.  The video concludes by promising future practical sessions on building machine learning models using popular datasets like the Iris dataset.\n",
            "\n"
          ]
        }
      ]
    }
  ]
}